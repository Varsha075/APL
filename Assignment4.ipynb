{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c10e7b2c-e916-46d8-a9d4-219206eb6b1e",
   "metadata": {},
   "source": [
    "# Assignment 4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113f53a5-f455-43a3-85d1-598125489aa3",
   "metadata": {},
   "source": [
    "## Read the netlist and sort the nets in the toplogical order\n",
    "To first read the netlist we define a function called `ckt` that opens the netlist and stores an array of gate ID, gate type, the two inputs and its corresponding node at output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "899ec5dd-70c7-4dd2-8027-f81974612887",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import cmath\n",
    "import networkx as nx\n",
    "from queue import Queue\n",
    "import sys\n",
    "import timeit\n",
    "def ckt(file):\n",
    "    try:\n",
    "        with open(file,'r') as f:\n",
    "            data=f.read().split(\"\\n\")\n",
    "    except Exception as ex:\n",
    "        print (ex)\n",
    "        return\n",
    "    gate_id=[]\n",
    "    gate_type=[]\n",
    "    input_1=[]\n",
    "    input_2=[]\n",
    "    output=[]\n",
    "    for l in data:\n",
    "        if l=='':\n",
    "            continue\n",
    "        i=l.split()\n",
    "        gate_id.append(i[0])\n",
    "        gate_type.append(i[1])\n",
    "        input_1.append(i[2])\n",
    "        if len(i)==4:\n",
    "            input_2.append(None)\n",
    "            output.append(i[3])\n",
    "        else:\n",
    "            input_2.append(i[3])\n",
    "            output.append(i[4])\n",
    "        \n",
    "    return gate_id,gate_type,input_1,input_2,output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffd97cd-e5b1-4db4-aae8-71d252bd0247",
   "metadata": {},
   "source": [
    "Once the netlist is read we try to print the nodes in topological order. This is done by using `nx.topological_sort` from Networkx. Let's see what it looks like for `c17` circuit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d040bf58-442a-4a7a-b159-8529f910ee64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The topological order of c17 netlist is : ['N2', 'N7', 'N1', 'N3', 'N6', 'n_0', 'n_1', 'n_3', 'n_2', 'N22', 'N23']\n"
     ]
    }
   ],
   "source": [
    "def topologicalorder(file):\n",
    "    gate_id,gate_type,input_1,input_2,output=ckt(file) #Reading the netlist\n",
    "\n",
    "    M=np.column_stack([gate_id,gate_type,input_1,input_2,output])\n",
    "\n",
    "    edges=[]\n",
    "    node_attributes={}     \n",
    "    primary=[]\n",
    "\n",
    "    for o in range(len(output)):\n",
    "        if M[o][3]!=None:\n",
    "            edges.append((M[o][2],M[o][4]))\n",
    "            edges.append((M[o][3],M[o][4]))\n",
    "        else:\n",
    "            edges.append((M[o][2],M[o][4]))\n",
    "        \n",
    "\n",
    "    for j in range(len(output)):\n",
    "        if M[j][2] not in output:\n",
    "            primary.append(M[j][2])\n",
    "        \n",
    "        if M[j][3] not in output:\n",
    "            primary.append(M[j][3])\n",
    "    primary_input=[*set(primary)]\n",
    "    for l in range(len(primary_input)):\n",
    "        node_attributes.__setitem__(primary_input[l],'PI')\n",
    "    for l in range(len(output)):\n",
    "        node_attributes.__setitem__(output[l],gate_type[l])\n",
    "    g = nx.DiGraph()\n",
    "    g.add_edges_from(edges)\n",
    "    nx.set_node_attributes(g,node_attributes,name=\"gateType\")\n",
    "    cycle=not nx.algorithms.dag.is_directed_acyclic_graph(g)\n",
    "    if cycle:\n",
    "        print('A cycle was detected')\n",
    "        sys.exit()\n",
    "    nodes=g.nodes(data=True)\n",
    "    nl = list(nx.topological_sort(g))\n",
    "    nlo = list(nx.lexicographical_topological_sort(g))\n",
    "    return nl,nlo,primary_input,nodes,g\n",
    "nl,nlo,primary_input,nodes,g=topologicalorder('c17.net') \n",
    "print(\"The topological order of c17 netlist is :\",nl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5c5d38-c120-4cea-9c96-4bbca71f74eb",
   "metadata": {},
   "source": [
    "Now we try to define functions for all possible combinational gates used in these netlist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ca4ecf5e-86e7-4234-8f0b-24bf7d3ecf8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AND(x,y):\n",
    "    return x and y\n",
    "def NAND(x,y):\n",
    "    if x == 1 and y == 1:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "def OR(x,y):\n",
    "    return x or y\n",
    "def XOR(x,y):\n",
    "    if x != y:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "def NOT(x):\n",
    "    if x == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "def BUF(x):\n",
    "    return x\n",
    "def NOR(x,y):\n",
    "    return NOT(OR(x,y))\n",
    "def XNOR(x,y):\n",
    "    return NOT(XOR(x,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04187d37-56eb-474a-a55b-481bd22f43ab",
   "metadata": {},
   "source": [
    "We define another function called `inp_ut` which returns all the input values in the `.input` file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7f65f665-b267-41b9-bfa7-af821439378f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inp_ut(file_inp):\n",
    "    try:\n",
    "        with open(file_inp,'r') as f:\n",
    "            data=f.read().split(\"\\n\")\n",
    "    except Exception as ex:\n",
    "        print (ex)\n",
    "        return\n",
    "\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8b9608-58eb-4a8a-b159-72ff2a45e9b5",
   "metadata": {},
   "source": [
    "## Read the list of input vectors, evaluate the circuit and find the state of all nets in the circuit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021f4a56-c999-49f9-b87c-df7c57055535",
   "metadata": {},
   "source": [
    "### Using Topoligical sort\n",
    "Now we define a fuction called `topologicalsort()` to solve and create a `.txt` file with the state of each node for all the inputs in `.inputs` file. \n",
    "Here, we first try to map the nodes read from `.input` file with their node type and then we run a loop across each line of input and write each nodes' state to the `txt` file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "237b54ca-fb7c-4e4d-be52-3a20fe3294ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.56 ms ± 81.9 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "def topologicalsort(file,file_inp,file_out):\n",
    "    \n",
    "    nl,nlo,primary_input,nodes,g=topologicalorder(file)\n",
    "\n",
    "    \n",
    "    data=inp_ut(file_inp)\n",
    "    valin=[]\n",
    "    for l in data:\n",
    "            if l=='':\n",
    "                continue\n",
    "            i=l.split()\n",
    "            valin.append(i)\n",
    "    res = [i for i in nl if i not in primary_input]\n",
    "    inpp=[i for i in nlo if i in primary_input]\n",
    "    identifiers = inpp\n",
    "    inp = sorted(identifiers)\n",
    "    nodes_type={}\n",
    "    for i in range(len(res)):\n",
    "        for item in nodes:\n",
    "            if res[i] in item:\n",
    "                nodes_type.__setitem__(res[i],item[1]['gateType'])\n",
    "    #print(nodes_type)\n",
    "    biinp={}\n",
    "    for l in range(1,len(valin)):\n",
    "        inp_dict={}\n",
    "        for k in range(len(inp)):\n",
    "            inp_dict.__setitem__(valin[0][k],valin[l][k])\n",
    "        for p in range(len(inp)):\n",
    "            biinp.__setitem__(inpp[p],inp_dict.get(inp[p])) \n",
    "        for i in range(len(res)):\n",
    "            if nodes_type[res[i]]=='nand2':\n",
    "                biinp.__setitem__(res[i],NAND(int(biinp[list(g.predecessors(res[i]))[0]]),int(biinp[list(g.predecessors(res[i]))[1]])))\n",
    "            \n",
    "            if nodes_type[res[i]]=='and2':\n",
    "                biinp.__setitem__(res[i],AND(int(biinp[list(g.predecessors(res[i]))[0]]),int(biinp[list(g.predecessors(res[i]))[1]])))\n",
    "                \n",
    "            if nodes_type[res[i]]=='or2':\n",
    "                biinp.__setitem__(res[i],OR(int(biinp[list(g.predecessors(res[i]))[0]]),int(biinp[list(g.predecessors(res[i]))[1]])))\n",
    "                \n",
    "            if nodes_type[res[i]]=='nor2':\n",
    "                biinp.__setitem__(res[i],NOR(int(biinp[list(g.predecessors(res[i]))[0]]),int(biinp[list(g.predecessors(res[i]))[1]])))\n",
    "                \n",
    "            if nodes_type[res[i]]=='inv':\n",
    "                biinp.__setitem__(res[i],NOT(int(biinp[list(g.predecessors(res[i]))[0]])))\n",
    "                \n",
    "            if nodes_type[res[i]]=='buf':\n",
    "                biinp.__setitem__(res[i],BUF(int(biinp[list(g.predecessors(res[i]))[0]])))\n",
    "                \n",
    "            if nodes_type[res[i]]=='xor2':\n",
    "                biinp.__setitem__(res[i],XOR(int(biinp[list(g.predecessors(res[i]))[0]]),int(biinp[list(g.predecessors(res[i]))[1]])))\n",
    "                \n",
    "            if nodes_type[res[i]]=='xnor2':\n",
    "                biinp.__setitem__(res[i],XNOR(int(biinp[list(g.predecessors(res[i]))[0]]),int(biinp[list(g.predecessors(res[i]))[1]])))\n",
    "               \n",
    "            \n",
    "        if l==1:\n",
    "            with open(file_out, 'a') as f:\n",
    "        # Write the headers to the file\n",
    "                headers =sorted(list(biinp.keys()))\n",
    "                f.write('\\t'.join(headers) + '\\n')   \n",
    "        headers =sorted(list(biinp.keys()))\n",
    "        outsort={}\n",
    "        for i in range(len(biinp)):\n",
    "            outsort.__setitem__(headers[i],biinp.get(headers[i]))\n",
    "        with open(file_out, 'r+') as f:\n",
    "            contents = f.read()\n",
    "            values=list(outsort.values())\n",
    "            f.write('\\t'.join(str(val) for val in values) + '\\n')\n",
    "        \n",
    "        \n",
    "topologicalsort('c17.net','c17.inputs','output.txt')       \n",
    "        \n",
    "#%timeit topologicalsort('c17.net','c17.inputs','output.txt')  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd53b1c-aab4-46c4-a5e0-5afe50f36d24",
   "metadata": {},
   "source": [
    "### Using Event driven\n",
    "Here, we first define lists of all the nodes, gate type and dictionaries of gate type. And define a dictionary initially as `final_set` with all the nodes as keys amd random values say -1 as values. We run a for loop for every input from `.input` file and assign it's values to corresponding 'PI'. We define a function called `check()` which checks for the changed inputs in inp_dict. Initailly as all the inputs are diffrent from final_set, we add all the inputs to the Queue. And for each `.get()` we append its successors to the queue. Once all the primary inputs are omitted out of the queue, as the `g.predecessors` of levels above zero is not None, the nodes start performing their respective the gate operations. Once all the elements of the queue are out, the states of the nodes are added to `.txt` file. Again we check for changed keys and do the gate opperations to only it's successors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "34621407-4d2b-40e1-babf-b2f48ce18940",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(inp_dict,final_set,Graph):\n",
    "    changed_keys = []\n",
    "    for key in inp_dict.keys():\n",
    "        if inp_dict[key] != final_set[key]:\n",
    "            tep=list(Graph.successors(key))\n",
    "            for i in tep:\n",
    "                pred=list(Graph.predecessors(i))\n",
    "                if key in pred:\n",
    "                    inp_keys=inp_dict.keys()\n",
    "                    if all(elem in inp_keys for elem in pred):\n",
    "                        for i in pred:\n",
    "                            if i!= key and final_set[i]!=final_set[key]:\n",
    "                                changed_keys.append(key)\n",
    "                            elif i!=key and final_set[key]!=inp_dict[i]:\n",
    "                                changed_keys.append(key)\n",
    "                            elif i!=key and final_set[i]!=inp_dict[key]:\n",
    "                                changed_keys.append(key)\n",
    "                            else:\n",
    "                                continue\n",
    "                    else:\n",
    "                        changed_keys.append(key)\n",
    "    changed_keys=[*set(changed_keys)]\n",
    "                    \n",
    "    return changed_keys\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f2a78cbe-1fe2-4d15-9b64-4fd17d1ce03a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.23 ms ± 24.2 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "def eventdriven(file,file_inp,file_out):\n",
    "    gate_id,gate_type,input_1,input_2,output=ckt(file)\n",
    "    M=np.column_stack([gate_id,gate_type,input_1,input_2,output])\n",
    "    edges=[]\n",
    "    node_attributes={}     \n",
    "    primary=[]\n",
    "    valin=[]\n",
    "    final_set={}\n",
    "    inp_dict={}\n",
    "    nodes_type={}\n",
    "    q=Queue()\n",
    "    for o in range(len(output)):\n",
    "        if M[o][3]!=None:\n",
    "            edges.append((M[o][2],M[o][4]))\n",
    "            edges.append((M[o][3],M[o][4]))\n",
    "        else:\n",
    "            edges.append((M[o][2],M[o][4]))\n",
    "        \n",
    "\n",
    "    for j in range(len(output)):\n",
    "        if M[j][2] not in output:\n",
    "            primary.append(M[j][2])\n",
    "        \n",
    "        if M[j][3] not in output:\n",
    "            primary.append(M[j][3])\n",
    "    primary_input=[*set(primary)]\n",
    "    for l in range(len(primary_input)):\n",
    "        node_attributes.__setitem__(primary_input[l],'PI')\n",
    "    for l in range(len(output)):\n",
    "        node_attributes.__setitem__(output[l],gate_type[l])\n",
    "    g1 = nx.DiGraph()\n",
    "    g1.add_edges_from(edges)\n",
    "    cycle=not nx.algorithms.dag.is_directed_acyclic_graph(g1)\n",
    "    if cycle:\n",
    "        print('A cycle was detected')\n",
    "        sys.exit()\n",
    "    nx.set_node_attributes(g1,node_attributes,name=\"gateType\")\n",
    "    nodes=g1.nodes(data=True)\n",
    "    data=inp_ut(file_inp)\n",
    "    for l in data:\n",
    "            if l=='':\n",
    "                continue\n",
    "            i=l.split()\n",
    "            valin.append(i)\n",
    "    nlo=[*set(input_1+input_2+output)]\n",
    "    res = [i for i in nlo if i not in primary_input]\n",
    "    inpp=[i for i in nlo if i in primary_input]\n",
    "    \n",
    "    \n",
    "    nlo=list(filter(lambda x: x is not None, nlo))\n",
    "    identifiers= list(filter(lambda x: x is not None, inpp))\n",
    "    inp = sorted(identifiers)\n",
    "   \n",
    "    for i in range(len(res)):\n",
    "        for item in nodes:\n",
    "            if res[i] in item:\n",
    "                nodes_type.__setitem__(res[i],item[1]['gateType'])\n",
    "\n",
    "    for i in nlo:\n",
    "        final_set.__setitem__(i,-1)\n",
    "    for l in range(1,len(valin)):\n",
    "        inp_dict={}\n",
    "        for k in range(len(inp)):\n",
    "            inp_dict.__setitem__(valin[0][k],valin[l][k])\n",
    "        \n",
    "        changed_keys=check(inp_dict,final_set,g1)\n",
    "        if len(changed_keys)>0:\n",
    "            q=Queue()\n",
    "            for pi_inputs in changed_keys:\n",
    "                q.put(pi_inputs)\n",
    "\n",
    "        while q.qsize()>0:\n",
    "            temp=q.get()\n",
    "            if  len(list(g1.predecessors(temp)))>0:\n",
    "                pre_keys=final_set.keys()\n",
    "                if all(elem in pre_keys for elem in list(g1.predecessors(temp))):\n",
    "\n",
    "                    for inputs in list(g1.successors(temp)):\n",
    "                        q.put(inputs)\n",
    "                    if nodes_type[temp]=='nand2':\n",
    "                        final_set[temp]=NAND(int(final_set[list(g1.predecessors(temp))[0]]),int(final_set[list(g1.predecessors(temp))[1]]))\n",
    "\n",
    "                    if nodes_type[temp]=='and2':\n",
    "                        final_set[temp]=AND(int(final_set[list(g1.predecessors(temp))[0]]),int(final_set[list(g1.predecessors(temp))[1]]))\n",
    "\n",
    "                    if nodes_type[temp]=='or2':\n",
    "                        final_set[temp]=OR(int(final_set[list(g1.predecessors(temp))[0]]),int(final_set[list(g1.predecessors(temp))[1]]))\n",
    "\n",
    "                    if nodes_type[temp]=='nor2':\n",
    "                        final_set[temp]=NOR(int(final_set[list(g1.predecessors(temp))[0]]),int(final_set[list(g1.predecessors(temp))[1]]))\n",
    "\n",
    "                    if nodes_type[temp]=='inv':\n",
    "                        final_set[temp]=NOT(int(final_set[list(g1.predecessors(temp))[0]]))\n",
    "\n",
    "                    if nodes_type[temp]=='buf':\n",
    "                        final_set[temp]=BUF(int(final_set[list(g1.predecessors(temp))[0]]))\n",
    "\n",
    "                    if nodes_type[temp]=='xor2':\n",
    "                        final_set[temp]=XOR(int(final_set[list(g1.predecessors(temp))[0]]),int(final_set[list(g1.predecessors(temp))[1]]))\n",
    "\n",
    "                    if nodes_type[temp]=='xnor2':\n",
    "                        final_set[temp]=XNOR(int(final_set[list(g1.predecessors(temp))[0]]),int(final_set[list(g1.predecessors(temp))[1]]))\n",
    "                else:\n",
    "\n",
    "                    continue\n",
    "\n",
    "            else:\n",
    "                final_set.__setitem__(temp,inp_dict.get(temp))\n",
    "                for inputs in list(g1.successors(temp)):\n",
    "                    q.put(inputs)\n",
    "        if l==1:\n",
    "            with open(file_out, 'a') as f:\n",
    "        # Write the headers to the file\n",
    "                headers =sorted(list(final_set.keys()))\n",
    "                f.write('\\t'.join(headers) + '\\n')   \n",
    "        headers =sorted(list(final_set.keys()))\n",
    "        outsort={}\n",
    "        for i in range(len(final_set)):\n",
    "            outsort.__setitem__(headers[i],final_set.get(headers[i]))\n",
    "        with open(file_out, 'r+') as f:\n",
    "            contents = f.read()\n",
    "            values=list(outsort.values())\n",
    "            f.write('\\t'.join(str(val) for val in values) + '\\n') \n",
    "    #This writes the new states of each node to the .txt file\n",
    "       \n",
    "\n",
    "\n",
    "eventdriven('c17.net','c17.inputs','output.txt')              \n",
    "                \n",
    "       \n",
    "\n",
    "#%timeit  eventdriven('c17.net','c17.inputs','output.txt')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3185cdc9-e189-49ea-99e3-8d968ea75f2a",
   "metadata": {},
   "source": [
    "## Briefly discuss your results: which approach is faster/more efficient, and for what types of inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac81c522-24d1-4b1f-b81e-d7aca7a0416c",
   "metadata": {},
   "source": [
    "As we understand from both the methods, topological and event driven, we can come to a conclusion that event driven is supposed to more faster, efficient compared to topological. This is because, in topological, we are using networkx to sort the nodes and running new set of inputs eventime we wanna know the change in state. However, in event driven we are applying gate operation only to the inputs with a change in their value. Therefore, we conclude that for any gven netlist, event driven methond is the most efficient and faster way to accquire state of each node."
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "Varsha S P, EE21B154 <ee21b154@smail.iitm.ac.in>"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
